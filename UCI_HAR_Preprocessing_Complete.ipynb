{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "266ab91a",
   "metadata": {},
   "source": [
    "# Human Activity Recognition (HAR) Preprocessing Notebook\n",
    "This notebook extracts time and frequency domain features from raw accelerometer and gyroscope signals in the UCI HAR Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3da793b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "import os\n",
    "\n",
    "# Mount Google Drive if using your own dataset\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Path to the unzipped UCI HAR Dataset (edit as needed)\n",
    "base_path = \"UCI HAR Dataset\"\n",
    "inertial_path = os.path.join(base_path, \"train\", \"Inertial Signals\") \n",
    "#This is where the raw intertial data is present\n",
    "\n",
    "# Function to load signal file\n",
    "def load_signal_file(filename):\n",
    "    return np.loadtxt(os.path.join(inertial_path, filename))\n",
    "\n",
    "# List of all 9 raw signal files\n",
    "signal_files = [\n",
    "    'body_acc_x_train.txt', 'body_acc_y_train.txt', 'body_acc_z_train.txt',\n",
    "    'body_gyro_x_train.txt', 'body_gyro_y_train.txt', 'body_gyro_z_train.txt',\n",
    "    'total_acc_x_train.txt', 'total_acc_y_train.txt', 'total_acc_z_train.txt'\n",
    "]\n",
    "\n",
    "# Load all signals into a dict\n",
    "raw_signals = {fname: load_signal_file(fname) for fname in signal_files}\n",
    "num_samples = raw_signals[signal_files[0]].shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad489f6",
   "metadata": {},
   "source": [
    "## Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "625d9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These features describe overall shape, energy, and trends in the signal. \n",
    "# For example, someone walking will have different acceleration magnitude compared to sitting.\n",
    "\n",
    "def extract_time_features(signal):\n",
    "    return [\n",
    "        np.mean(signal),\n",
    "        np.std(signal),\n",
    "        np.min(signal),\n",
    "        np.max(signal),\n",
    "        np.median(signal),\n",
    "        np.sum(signal**2) / len(signal),  # energy\n",
    "        np.sum(np.abs(signal)) / len(signal),  # SMA\n",
    "    ]\n",
    "\n",
    "#Human movements have rhythmic components (like walking), which show up as peaks in frequency space.\n",
    "def extract_freq_features(signal):\n",
    "    freq = np.abs(fft(signal)) #apply fast fourier transform to look at how much signal lies in different frequency bands\n",
    "    return [\n",
    "        np.mean(freq), #average magnitude of frequency spectrum\n",
    "        np.std(freq), #spread of frequency distribution\n",
    "        np.argmax(freq), #Index of highest peak in FFT (can represent periodic movement)\n",
    "        np.sum(freq**2) / len(freq) #Energy of the signal in the frequency domain\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f56f8",
   "metadata": {},
   "source": [
    "## Extract Features for All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4d68270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated feature matrix shape: (7352, 99)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract features for all samples\n",
    "all_features = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    features = []\n",
    "    for fname in signal_files:\n",
    "        signal = raw_signals[fname][i]\n",
    "        features.extend(extract_time_features(signal))\n",
    "        features.extend(extract_freq_features(signal))\n",
    "    all_features.append(features)\n",
    "\n",
    "X_train_generated = np.array(all_features)\n",
    "print(f\"Generated feature matrix shape: {X_train_generated.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f942a",
   "metadata": {},
   "source": [
    "## Load Labels (`y_train`, `y_test`) and Define Activity Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b14c311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample y_train: [5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load activity labels\n",
    "y_train = np.loadtxt(os.path.join(base_path, \"train\", \"y_train.txt\")).astype(int)\n",
    "y_test = np.loadtxt(os.path.join(base_path, \"test\", \"y_test.txt\")).astype(int)\n",
    "\n",
    "# Optional: Map label to activity name\n",
    "activity_map = {\n",
    "    1: \"WALKING\",\n",
    "    2: \"WALKING_UPSTAIRS\",\n",
    "    3: \"WALKING_DOWNSTAIRS\",\n",
    "    4: \"SITTING\",\n",
    "    5: \"STANDING\",\n",
    "    6: \"LAYING\"\n",
    "}\n",
    "print(\"Sample y_train:\", y_train[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524305e4",
   "metadata": {},
   "source": [
    "## Process `test/Inertial Signals` to Generate `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af2a809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated X_test shape: (2947, 99)\n"
     ]
    }
   ],
   "source": [
    "# List of all 9 raw signal files\n",
    "signal_files = [\n",
    "    'body_acc_x_test.txt', 'body_acc_y_test.txt', 'body_acc_z_test.txt',\n",
    "    'body_gyro_x_test.txt', 'body_gyro_y_test.txt', 'body_gyro_z_test.txt',\n",
    "    'total_acc_x_test.txt', 'total_acc_y_test.txt', 'total_acc_z_test.txt'\n",
    "]\n",
    "# Load test inertial signals\n",
    "test_inertial_path = os.path.join(base_path, \"test\", \"Inertial Signals\")\n",
    "test_signals = {fname: np.loadtxt(os.path.join(test_inertial_path, fname)) for fname in signal_files}\n",
    "num_test_samples = test_signals[signal_files[0]].shape[0]\n",
    "\n",
    "# Extract features for all test samples\n",
    "test_features = []\n",
    "for i in range(num_test_samples):\n",
    "    features = []\n",
    "    for fname in signal_files:\n",
    "        signal = test_signals[fname][i]\n",
    "        features.extend(extract_time_features(signal))\n",
    "        features.extend(extract_freq_features(signal))\n",
    "    test_features.append(features)\n",
    "\n",
    "X_test_generated = np.array(test_features)\n",
    "print(f\"Generated X_test shape: {X_test_generated.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6828d6",
   "metadata": {},
   "source": [
    "## Save All Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d4f5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(\"X_train_archana.txt\", X_train_generated)\n",
    "np.savetxt(\"X_test_archana.txt\", X_test_generated)\n",
    "np.savetxt(\"y_train_archana.txt\", y_train)\n",
    "np.savetxt(\"y_test_archana.txt\", y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
